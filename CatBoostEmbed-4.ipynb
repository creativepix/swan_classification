{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EozRhLPVicYj"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'autogluon'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcatboost\u001b[39;00m \u001b[39mimport\u001b[39;00m CatBoostClassifier,Pool,cv\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mautogluon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtabular\u001b[39;00m \u001b[39mimport\u001b[39;00m TabularDataset, TabularPredictor\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'autogluon'"
          ]
        }
      ],
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn import metrics as m\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import os\n",
        "import torch\n",
        "from catboost import CatBoostClassifier,Pool,cv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5Qe4FaztkYzK"
      },
      "outputs": [],
      "source": [
        "df = pd.read_json('/content/drive/MyDrive/clip_embed.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "phy0hYVSkcaX"
      },
      "outputs": [],
      "source": [
        "train_data,test_data = train_test_split(super_embed.drop([1],axis=1),train_size=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_fLHfLBy-3f",
        "outputId": "f897fbbf-fb01-48b3-f3e7-c883824bdffc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "/kaggle/working/klikun/images/3465518321.jpg            1\n",
              "/kaggle/working/разметка_малый/images/3802776664.jpg    1\n",
              "/kaggle/working/разметка_малый/images/3722784550.jpg    1\n",
              "/kaggle/working/разметка_малый/images/4039343899.jpg    1\n",
              "/kaggle/working/разметка_малый/images/3728254754.jpg    1\n",
              "                                                       ..\n",
              "/kaggle/working/klikun/images/24_Inosov_0776.jpg        1\n",
              "/kaggle/working/klikun/images/3077972978.jpg            1\n",
              "/kaggle/working/klikun/images/3760399311.jpg            1\n",
              "/kaggle/working/klikun/images/3822867290.jpg            1\n",
              "/kaggle/working/разметка_шипун/images/img_619.jpg       1\n",
              "Name: 1, Length: 8964, dtype: int64"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "super_embed[1].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYAR15Og4nd1",
        "outputId": "d3e77def-a292-47d0-8924-0d9df2f2bc69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8927"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(super_embed[4].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YaZ-zQs45GF",
        "outputId": "90d88a53-3724-4eab-878b-773c45bada4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8964"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XD8ivm7yiuzA",
        "outputId": "469fe9f9-e7f3-45fc-f967-cfcb4748c75d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230520_155618/\"\n",
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (7171 samples, 145.6 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230520_155618/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023\n",
            "Train Data Rows:    7171\n",
            "Train Data Columns: 2536\n",
            "Label Column: 0\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
            "\t3 unique label values:  [2, 0, 1]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    9457.36 MB\n",
            "\tTrain Data (Original)  Memory Usage: 145.49 MB (1.5% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2536 | ['2', '3', '4', '5', '6', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2536 | ['2', '3', '4', '5', '6', ...]\n",
            "\t5.7s = Fit runtime\n",
            "\t2536 features in original data used to generate 2536 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 145.49 MB (1.5% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 6.15s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6453, Val Rows: 718\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.9135\t = Validation score   (f1_weighted)\n",
            "\t1.03s\t = Training   runtime\n",
            "\t0.66s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.9137\t = Validation score   (f1_weighted)\n",
            "\t1.15s\t = Training   runtime\n",
            "\t1.16s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.9944\t = Validation score   (f1_weighted)\n",
            "\t25.38s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\tTraining LightGBMXT with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, X_val, y_val, time_limit, num_gpus, num_cpus, sample_weight, sample_weight_val, verbosity, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   2609\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2610\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0m\u001b[1;32m   2611\u001b[0m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLightGBMError\u001b[0m: GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0e01c8aa1531>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTabularPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1_weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/decorators.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mother_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_inner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0maux_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit_weighted_ensemble'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Save predictor to disk to enable prediction and training after interrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m         self._learner.fit(X=train_data, X_val=tuning_data, X_unlabeled=unlabeled_data,\n\u001b[0m\u001b[1;32m    867\u001b[0m                           \u001b[0mholdout_frac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mholdout_frac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bag_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_bag_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bag_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_bag_sets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m                           \u001b[0mnum_stack_levels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_stack_levels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Learner is already fit.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_fit_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     def _fit(self, X: DataFrame, X_val: DataFrame = None, scheduler_options=None, hyperparameter_tune=False,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/learner/default_learner.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         trainer.fit(\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/trainer/auto_trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m                                      '\\tpredictor.fit(..., tuning_data=tuning_data, use_bag_holdout=True)')\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         self._train_multi_and_ensemble(X=X,\n\u001b[0m\u001b[1;32m     99\u001b[0m                                        \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                                        \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_and_ensemble\u001b[0;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[1;32m   2049\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_rows_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_cols_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2051\u001b[0;31m         model_names_fit = self.train_multi_levels(X, y, hyperparameters=hyperparameters, X_val=X_val, y_val=y_val,\n\u001b[0m\u001b[1;32m   2052\u001b[0m                                                   X_unlabeled=X_unlabeled, level_start=1, level_end=num_stack_levels+1, time_limit=time_limit, **kwargs)\n\u001b[1;32m   2053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mtrain_multi_levels\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0mcore_kwargs_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_limit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_kwargs_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time_limit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit_core\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0maux_kwargs_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_limit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_kwargs_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time_limit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit_aux\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             base_model_names, aux_models = self.stack_new_level(\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_unlabeled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_unlabeled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_model_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mstack_new_level\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mcore_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name_suffix'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name_suffix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname_suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0maux_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name_suffix'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name_suffix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname_suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         core_models = self.stack_new_level_core(X=X, y=y, X_val=X_val, y_val=y_val, X_unlabeled=X_unlabeled, models=models,\n\u001b[0m\u001b[1;32m    430\u001b[0m                                                 level=level, infer_limit=infer_limit, infer_limit_batch_size=infer_limit_batch_size, base_model_names=base_model_names, **core_kwargs)\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mstack_new_level_core\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         return self._train_multi(X=X_init, y=y, X_val=X_val, y_val=y_val, X_unlabeled=X_unlabeled,\n\u001b[0m\u001b[1;32m    521\u001b[0m                                  models=models, level=level, stack_name=stack_name, compute_score=compute_score, fit_kwargs=fit_kwargs, **kwargs)\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi\u001b[0;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, **kwargs)\u001b[0m\n\u001b[1;32m   2019\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_repeat_start\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m             \u001b[0mtime_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m             model_names_trained = self._train_multi_initial(X=X, y=y, models=models, k_fold=k_fold, n_repeats=n_repeats_initial, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n\u001b[0m\u001b[1;32m   2022\u001b[0m                                                             feature_prune_kwargs=feature_prune_kwargs, time_limit=time_limit, **kwargs)\n\u001b[1;32m   2023\u001b[0m             \u001b[0mn_repeat_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_repeats_initial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_initial\u001b[0;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1911\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbagged\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m             \u001b[0mtime_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhpo_time_ratio\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhpo_enabled\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1913\u001b[0;31m             models = self._train_multi_fold(models=models, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n\u001b[0m\u001b[1;32m   1914\u001b[0m                                             time_limit=time_limit, time_split=time_split, time_ratio=time_ratio, **fit_args)\n\u001b[1;32m   1915\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_fold\u001b[0;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1990\u001b[0m                     \u001b[0mtime_start_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m                     \u001b[0mtime_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_limit\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime_start_model\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1992\u001b[0;31m             \u001b[0mmodel_name_trained_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_single_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameter_tune_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameter_tune_kwargs_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_single_full\u001b[0;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                 \u001b[0mbagged_model_fit_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_bagged_model_fit_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_fold_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_fold_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_repeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeat_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_repeat_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                 \u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbagged_model_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1810\u001b[0;31m             model_names_trained = self._train_and_save(\n\u001b[0m\u001b[1;32m   1811\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_and_save\u001b[0;34m(self, X, y, model, X_val, y_val, stack_name, level, compute_score, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_w_pseudo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_w_pseudo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_resources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_resources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m             \u001b[0mfit_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_single\u001b[0;34m(self, X, y, model, X_val, y_val, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \"\"\"\n\u001b[0;32m-> 1447\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_resources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_resources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1448\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_fit_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_fit_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, X_val, y_val, time_limit, num_gpus, num_cpus, sample_weight, sample_weight_val, verbosity, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m                                    )\n\u001b[1;32m    196\u001b[0m                     \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m             \u001b[0mretrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'boosting_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'dart'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    290\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3019\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3020\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3021\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   3022\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 ctypes.byref(is_finished)))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "predictor = TabularPredictor(label=0,eval_metric='f1_weighted').fit(train_data,num_gpus=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "PjfSoUL4kz3H",
        "outputId": "7b77c846-c2f0-4c86-a183-4a93ea1ad7b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  model  score_test  score_val  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0   WeightedEnsemble_L2    0.946330   0.958141        2.095053       1.040706  367.465576                 0.006284                0.002449           2.216262            2       True         14\n",
            "1        NeuralNetTorch    0.945780   0.949738        0.043614       0.029637   21.725185                 0.043614                0.029637          21.725185            1       True         12\n",
            "2       NeuralNetFastAI    0.940793   0.952564        0.155018       0.039688   15.422325                 0.155018                0.039688          15.422325            1       True          3\n",
            "3               XGBoost    0.932808   0.922980        0.434054       0.199338   33.613446                 0.434054                0.199338          33.613446            1       True         11\n",
            "4            LightGBMXT    0.932338   0.925916        0.367487       0.118830  241.936384                 0.367487                0.118830         241.936384            1       True          4\n",
            "5              LightGBM    0.931289   0.914524        0.232640       0.103882  269.057187                 0.232640                0.103882         269.057187            1       True          5\n",
            "6              CatBoost    0.926701   0.908939        0.055557       0.040767   25.778524                 0.055557                0.040767          25.778524            1       True          8\n",
            "7         LightGBMLarge    0.904680   0.903231        0.267398       0.080914  621.820032                 0.267398                0.080914         621.820032            1       True         13\n",
            "8      RandomForestGini    0.889364   0.874945        0.177728       0.165718   54.403005                 0.177728                0.165718          54.403005            1       True          6\n",
            "9        ExtraTreesEntr    0.885373   0.869236        0.227469       0.163710    8.590983                 0.227469                0.163710           8.590983            1       True         10\n",
            "10     RandomForestEntr    0.883256   0.870737        0.156187       0.102202   54.027626                 0.156187                0.102202          54.027626            1       True          7\n",
            "11       ExtraTreesGini    0.881517   0.859410        0.207950       0.152236    5.945063                 0.207950                0.152236           5.945063            1       True          9\n",
            "12       KNeighborsDist    0.877912   0.861138        1.102956       0.554898    0.414206                 1.102956                0.554898           0.414206            1       True          2\n",
            "13       KNeighborsUnif    0.877282   0.856715        1.008203       0.595759    0.423752                 1.008203                0.595759           0.423752            1       True          1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6a0809a7-5400-4346-a181-c12daa9ddbea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_test</th>\n",
              "      <th>score_val</th>\n",
              "      <th>pred_time_test</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_test_marginal</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.946330</td>\n",
              "      <td>0.958141</td>\n",
              "      <td>2.095053</td>\n",
              "      <td>1.040706</td>\n",
              "      <td>367.465576</td>\n",
              "      <td>0.006284</td>\n",
              "      <td>0.002449</td>\n",
              "      <td>2.216262</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NeuralNetTorch</td>\n",
              "      <td>0.945780</td>\n",
              "      <td>0.949738</td>\n",
              "      <td>0.043614</td>\n",
              "      <td>0.029637</td>\n",
              "      <td>21.725185</td>\n",
              "      <td>0.043614</td>\n",
              "      <td>0.029637</td>\n",
              "      <td>21.725185</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NeuralNetFastAI</td>\n",
              "      <td>0.940793</td>\n",
              "      <td>0.952564</td>\n",
              "      <td>0.155018</td>\n",
              "      <td>0.039688</td>\n",
              "      <td>15.422325</td>\n",
              "      <td>0.155018</td>\n",
              "      <td>0.039688</td>\n",
              "      <td>15.422325</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.932808</td>\n",
              "      <td>0.922980</td>\n",
              "      <td>0.434054</td>\n",
              "      <td>0.199338</td>\n",
              "      <td>33.613446</td>\n",
              "      <td>0.434054</td>\n",
              "      <td>0.199338</td>\n",
              "      <td>33.613446</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LightGBMXT</td>\n",
              "      <td>0.932338</td>\n",
              "      <td>0.925916</td>\n",
              "      <td>0.367487</td>\n",
              "      <td>0.118830</td>\n",
              "      <td>241.936384</td>\n",
              "      <td>0.367487</td>\n",
              "      <td>0.118830</td>\n",
              "      <td>241.936384</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.931289</td>\n",
              "      <td>0.914524</td>\n",
              "      <td>0.232640</td>\n",
              "      <td>0.103882</td>\n",
              "      <td>269.057187</td>\n",
              "      <td>0.232640</td>\n",
              "      <td>0.103882</td>\n",
              "      <td>269.057187</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.926701</td>\n",
              "      <td>0.908939</td>\n",
              "      <td>0.055557</td>\n",
              "      <td>0.040767</td>\n",
              "      <td>25.778524</td>\n",
              "      <td>0.055557</td>\n",
              "      <td>0.040767</td>\n",
              "      <td>25.778524</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LightGBMLarge</td>\n",
              "      <td>0.904680</td>\n",
              "      <td>0.903231</td>\n",
              "      <td>0.267398</td>\n",
              "      <td>0.080914</td>\n",
              "      <td>621.820032</td>\n",
              "      <td>0.267398</td>\n",
              "      <td>0.080914</td>\n",
              "      <td>621.820032</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RandomForestGini</td>\n",
              "      <td>0.889364</td>\n",
              "      <td>0.874945</td>\n",
              "      <td>0.177728</td>\n",
              "      <td>0.165718</td>\n",
              "      <td>54.403005</td>\n",
              "      <td>0.177728</td>\n",
              "      <td>0.165718</td>\n",
              "      <td>54.403005</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ExtraTreesEntr</td>\n",
              "      <td>0.885373</td>\n",
              "      <td>0.869236</td>\n",
              "      <td>0.227469</td>\n",
              "      <td>0.163710</td>\n",
              "      <td>8.590983</td>\n",
              "      <td>0.227469</td>\n",
              "      <td>0.163710</td>\n",
              "      <td>8.590983</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RandomForestEntr</td>\n",
              "      <td>0.883256</td>\n",
              "      <td>0.870737</td>\n",
              "      <td>0.156187</td>\n",
              "      <td>0.102202</td>\n",
              "      <td>54.027626</td>\n",
              "      <td>0.156187</td>\n",
              "      <td>0.102202</td>\n",
              "      <td>54.027626</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ExtraTreesGini</td>\n",
              "      <td>0.881517</td>\n",
              "      <td>0.859410</td>\n",
              "      <td>0.207950</td>\n",
              "      <td>0.152236</td>\n",
              "      <td>5.945063</td>\n",
              "      <td>0.207950</td>\n",
              "      <td>0.152236</td>\n",
              "      <td>5.945063</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>KNeighborsDist</td>\n",
              "      <td>0.877912</td>\n",
              "      <td>0.861138</td>\n",
              "      <td>1.102956</td>\n",
              "      <td>0.554898</td>\n",
              "      <td>0.414206</td>\n",
              "      <td>1.102956</td>\n",
              "      <td>0.554898</td>\n",
              "      <td>0.414206</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>KNeighborsUnif</td>\n",
              "      <td>0.877282</td>\n",
              "      <td>0.856715</td>\n",
              "      <td>1.008203</td>\n",
              "      <td>0.595759</td>\n",
              "      <td>0.423752</td>\n",
              "      <td>1.008203</td>\n",
              "      <td>0.595759</td>\n",
              "      <td>0.423752</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a0809a7-5400-4346-a181-c12daa9ddbea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a0809a7-5400-4346-a181-c12daa9ddbea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a0809a7-5400-4346-a181-c12daa9ddbea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
              "0   WeightedEnsemble_L2    0.946330   0.958141        2.095053       1.040706   \n",
              "1        NeuralNetTorch    0.945780   0.949738        0.043614       0.029637   \n",
              "2       NeuralNetFastAI    0.940793   0.952564        0.155018       0.039688   \n",
              "3               XGBoost    0.932808   0.922980        0.434054       0.199338   \n",
              "4            LightGBMXT    0.932338   0.925916        0.367487       0.118830   \n",
              "5              LightGBM    0.931289   0.914524        0.232640       0.103882   \n",
              "6              CatBoost    0.926701   0.908939        0.055557       0.040767   \n",
              "7         LightGBMLarge    0.904680   0.903231        0.267398       0.080914   \n",
              "8      RandomForestGini    0.889364   0.874945        0.177728       0.165718   \n",
              "9        ExtraTreesEntr    0.885373   0.869236        0.227469       0.163710   \n",
              "10     RandomForestEntr    0.883256   0.870737        0.156187       0.102202   \n",
              "11       ExtraTreesGini    0.881517   0.859410        0.207950       0.152236   \n",
              "12       KNeighborsDist    0.877912   0.861138        1.102956       0.554898   \n",
              "13       KNeighborsUnif    0.877282   0.856715        1.008203       0.595759   \n",
              "\n",
              "      fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
              "0   367.465576                 0.006284                0.002449   \n",
              "1    21.725185                 0.043614                0.029637   \n",
              "2    15.422325                 0.155018                0.039688   \n",
              "3    33.613446                 0.434054                0.199338   \n",
              "4   241.936384                 0.367487                0.118830   \n",
              "5   269.057187                 0.232640                0.103882   \n",
              "6    25.778524                 0.055557                0.040767   \n",
              "7   621.820032                 0.267398                0.080914   \n",
              "8    54.403005                 0.177728                0.165718   \n",
              "9     8.590983                 0.227469                0.163710   \n",
              "10   54.027626                 0.156187                0.102202   \n",
              "11    5.945063                 0.207950                0.152236   \n",
              "12    0.414206                 1.102956                0.554898   \n",
              "13    0.423752                 1.008203                0.595759   \n",
              "\n",
              "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
              "0            2.216262            2       True         14  \n",
              "1           21.725185            1       True         12  \n",
              "2           15.422325            1       True          3  \n",
              "3           33.613446            1       True         11  \n",
              "4          241.936384            1       True          4  \n",
              "5          269.057187            1       True          5  \n",
              "6           25.778524            1       True          8  \n",
              "7          621.820032            1       True         13  \n",
              "8           54.403005            1       True          6  \n",
              "9            8.590983            1       True         10  \n",
              "10          54.027626            1       True          7  \n",
              "11           5.945063            1       True          9  \n",
              "12           0.414206            1       True          2  \n",
              "13           0.423752            1       True          1  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.leaderboard(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE7fFJGxsMyS",
        "outputId": "9aec345a-0d93-4125-f25c-54073034cd6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "predictor.save('clip_embed_predictor/predictor.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cec8itiJtNG3"
      },
      "outputs": [],
      "source": [
        "from autogluon.tabular.models import AbstractModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z2dI7Bmttb2"
      },
      "outputs": [],
      "source": [
        "model = TabularPredictor.load('/content/AutogluonModels/ag-20230519_200219')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLt6IYd6txjL"
      },
      "outputs": [],
      "source": [
        "model.leaderboard(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "Q6ueZKn-uSIB",
        "outputId": "3a21cec1-acda-4441-d747-771cad8949b8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/clip_autogluon.zip'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "shutil.make_archive('clip_autogluon', 'zip', '/content/AutogluonModels/ag-20230519_200219')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bBHgdHIkuzFx"
      },
      "outputs": [],
      "source": [
        "timm_df = pd.read_json('/content/drive/MyDrive/convnext_xxlarge.clip_laion2b_embed.json') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7VrKQZ5-0Bs5"
      },
      "outputs": [],
      "source": [
        "timm_df2 = pd.read_json('/content/drive/MyDrive/eva02_large_patch14_clip_336.merged2b_embed.json') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beol6QxzyI4N"
      },
      "outputs": [],
      "source": [
        "timm_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vptSSBbNx7wD"
      },
      "outputs": [],
      "source": [
        "super_embed = pd.concat([df,timm_df.drop(['indexes','cls'],axis=1),\n",
        "                         timm_df2.drop(['indexes','cls'],axis=1)],axis=1,ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2fktMTSyPft",
        "outputId": "c16a5a0b-a8e7-45fe-e5aa-9991ed17541a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/kaggle/working/catboost_info': No such file or directory\n",
            "Training on fold [0/5]\n",
            "bestTest = 0.9665719611\n",
            "bestIteration = 394\n",
            "Training on fold [1/5]\n",
            "bestTest = 0.9693017235\n",
            "bestIteration = 399\n",
            "Training on fold [2/5]\n",
            "bestTest = 0.9687154503\n",
            "bestIteration = 356\n",
            "Training on fold [3/5]\n",
            "bestTest = 0.9598273178\n",
            "bestIteration = 378\n",
            "Training on fold [4/5]\n",
            "bestTest = 0.9732000403\n",
            "bestIteration = 392\n"
          ]
        }
      ],
      "source": [
        "!rm -r /kaggle/working/catboost_info\n",
        "from catboost import CatBoostClassifier,Pool,cv\n",
        "params = {'iterations':400,\n",
        "         'loss_function':'MultiClass',\n",
        "         'random_seed':42,\n",
        "         'eval_metric':'TotalF1:average=Weighted',\n",
        "         'task_type':'GPU'}\n",
        "train_pool = Pool(data = super_embed.drop([0,1],axis=1),\n",
        "                 label = super_embed[0])\n",
        "cv_data = cv(train_pool,\n",
        "            params = params,\n",
        "            fold_count = 5,\n",
        "            shuffle = True,\n",
        "            stratified =True,\n",
        "            verbose = False,\n",
        "            seed = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "e9DT_DxrzrP_",
        "outputId": "5ad5ee0d-2519-48cc-8f4e-77c91cb47a27"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-23077509-e67b-4856-8855-490c72004772\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>iterations</th>\n",
              "      <th>test-TotalF1:average=Weighted-mean</th>\n",
              "      <th>test-TotalF1:average=Weighted-std</th>\n",
              "      <th>train-TotalF1:average=Weighted-mean</th>\n",
              "      <th>train-TotalF1:average=Weighted-std</th>\n",
              "      <th>test-MultiClass-mean</th>\n",
              "      <th>test-MultiClass-std</th>\n",
              "      <th>train-MultiClass-mean</th>\n",
              "      <th>train-MultiClass-std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.783331</td>\n",
              "      <td>0.014191</td>\n",
              "      <td>0.798884</td>\n",
              "      <td>0.005927</td>\n",
              "      <td>1.067108</td>\n",
              "      <td>0.000688</td>\n",
              "      <td>1.066097</td>\n",
              "      <td>0.000465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.811545</td>\n",
              "      <td>0.015209</td>\n",
              "      <td>0.828390</td>\n",
              "      <td>0.006741</td>\n",
              "      <td>1.037377</td>\n",
              "      <td>0.000862</td>\n",
              "      <td>1.035471</td>\n",
              "      <td>0.000570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.827067</td>\n",
              "      <td>0.009863</td>\n",
              "      <td>0.841591</td>\n",
              "      <td>0.010630</td>\n",
              "      <td>1.009053</td>\n",
              "      <td>0.000725</td>\n",
              "      <td>1.006508</td>\n",
              "      <td>0.000515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.828403</td>\n",
              "      <td>0.013024</td>\n",
              "      <td>0.844849</td>\n",
              "      <td>0.008346</td>\n",
              "      <td>0.982991</td>\n",
              "      <td>0.001158</td>\n",
              "      <td>0.979435</td>\n",
              "      <td>0.000560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.834939</td>\n",
              "      <td>0.010559</td>\n",
              "      <td>0.850846</td>\n",
              "      <td>0.010050</td>\n",
              "      <td>0.958027</td>\n",
              "      <td>0.000952</td>\n",
              "      <td>0.953895</td>\n",
              "      <td>0.000755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>395</td>\n",
              "      <td>0.947858</td>\n",
              "      <td>0.006441</td>\n",
              "      <td>0.984376</td>\n",
              "      <td>0.000743</td>\n",
              "      <td>0.156364</td>\n",
              "      <td>0.006850</td>\n",
              "      <td>0.099819</td>\n",
              "      <td>0.001804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>396</td>\n",
              "      <td>0.947747</td>\n",
              "      <td>0.006594</td>\n",
              "      <td>0.984376</td>\n",
              "      <td>0.000875</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>0.006828</td>\n",
              "      <td>0.099655</td>\n",
              "      <td>0.001830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>397</td>\n",
              "      <td>0.947630</td>\n",
              "      <td>0.006692</td>\n",
              "      <td>0.984403</td>\n",
              "      <td>0.000771</td>\n",
              "      <td>0.156154</td>\n",
              "      <td>0.006838</td>\n",
              "      <td>0.099488</td>\n",
              "      <td>0.001842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>398</td>\n",
              "      <td>0.947740</td>\n",
              "      <td>0.006603</td>\n",
              "      <td>0.984459</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>0.156035</td>\n",
              "      <td>0.006859</td>\n",
              "      <td>0.099296</td>\n",
              "      <td>0.001799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>399</td>\n",
              "      <td>0.947735</td>\n",
              "      <td>0.006424</td>\n",
              "      <td>0.984571</td>\n",
              "      <td>0.000671</td>\n",
              "      <td>0.155891</td>\n",
              "      <td>0.006813</td>\n",
              "      <td>0.099122</td>\n",
              "      <td>0.001809</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23077509-e67b-4856-8855-490c72004772')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-23077509-e67b-4856-8855-490c72004772 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-23077509-e67b-4856-8855-490c72004772');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     iterations  test-TotalF1:average=Weighted-mean  \\\n",
              "0             0                            0.783331   \n",
              "1             1                            0.811545   \n",
              "2             2                            0.827067   \n",
              "3             3                            0.828403   \n",
              "4             4                            0.834939   \n",
              "..          ...                                 ...   \n",
              "395         395                            0.947858   \n",
              "396         396                            0.947747   \n",
              "397         397                            0.947630   \n",
              "398         398                            0.947740   \n",
              "399         399                            0.947735   \n",
              "\n",
              "     test-TotalF1:average=Weighted-std  train-TotalF1:average=Weighted-mean  \\\n",
              "0                             0.014191                             0.798884   \n",
              "1                             0.015209                             0.828390   \n",
              "2                             0.009863                             0.841591   \n",
              "3                             0.013024                             0.844849   \n",
              "4                             0.010559                             0.850846   \n",
              "..                                 ...                                  ...   \n",
              "395                           0.006441                             0.984376   \n",
              "396                           0.006594                             0.984376   \n",
              "397                           0.006692                             0.984403   \n",
              "398                           0.006603                             0.984459   \n",
              "399                           0.006424                             0.984571   \n",
              "\n",
              "     train-TotalF1:average=Weighted-std  test-MultiClass-mean  \\\n",
              "0                              0.005927              1.067108   \n",
              "1                              0.006741              1.037377   \n",
              "2                              0.010630              1.009053   \n",
              "3                              0.008346              0.982991   \n",
              "4                              0.010050              0.958027   \n",
              "..                                  ...                   ...   \n",
              "395                            0.000743              0.156364   \n",
              "396                            0.000875              0.156250   \n",
              "397                            0.000771              0.156154   \n",
              "398                            0.000700              0.156035   \n",
              "399                            0.000671              0.155891   \n",
              "\n",
              "     test-MultiClass-std  train-MultiClass-mean  train-MultiClass-std  \n",
              "0               0.000688               1.066097              0.000465  \n",
              "1               0.000862               1.035471              0.000570  \n",
              "2               0.000725               1.006508              0.000515  \n",
              "3               0.001158               0.979435              0.000560  \n",
              "4               0.000952               0.953895              0.000755  \n",
              "..                   ...                    ...                   ...  \n",
              "395             0.006850               0.099819              0.001804  \n",
              "396             0.006828               0.099655              0.001830  \n",
              "397             0.006838               0.099488              0.001842  \n",
              "398             0.006859               0.099296              0.001799  \n",
              "399             0.006813               0.099122              0.001809  \n",
              "\n",
              "[400 rows x 9 columns]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1xO9GKayqIi",
        "outputId": "4d0a4de8-9935-4f64-af28-aa276e6bbe0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9481939404440538"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_data['test-TotalF1:average=Weighted-mean'].max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMWCCZW90jAf"
      },
      "source": [
        "# Autogluon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4Toy6lM049W"
      },
      "outputs": [],
      "source": [
        "train_data,test_data = train_test_split(super_embed.drop([1],axis=1),train_size=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVPFzQLS0o1y",
        "outputId": "96bdb51e-09e0-4117-abdb-5c266bc3acbb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230519_210435/\"\n",
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (7171 samples, 101.54 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230519_210435/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023\n",
            "Train Data Rows:    7171\n",
            "Train Data Columns: 1768\n",
            "Label Column: 0\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
            "\t3 unique label values:  [0, 2, 1]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    6774.52 MB\n",
            "\tTrain Data (Original)  Memory Usage: 101.43 MB (1.5% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 1768 | ['2', '3', '4', '5', '6', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 1768 | ['2', '3', '4', '5', '6', ...]\n",
            "\t3.9s = Fit runtime\n",
            "\t1768 features in original data used to generate 1768 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 101.43 MB (1.5% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 4.4s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 6453, Val Rows: 718\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.8868\t = Validation score   (f1_weighted)\n",
            "\t0.62s\t = Training   runtime\n",
            "\t0.57s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.8868\t = Validation score   (f1_weighted)\n",
            "\t0.63s\t = Training   runtime\n",
            "\t0.58s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.9805\t = Validation score   (f1_weighted)\n",
            "\t16.83s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\tTraining LightGBMXT with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\t0.9666\t = Validation score   (f1_weighted)\n",
            "\t478.27s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\tTraining LightGBM with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\t0.9666\t = Validation score   (f1_weighted)\n",
            "\t546.9s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.9245\t = Validation score   (f1_weighted)\n",
            "\t70.53s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.9288\t = Validation score   (f1_weighted)\n",
            "\t86.42s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\t'colsample_bylevel' is not supported on GPU, using default value (Default = 1).\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\t0.9749\t = Validation score   (f1_weighted)\n",
            "\t118.23s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.923\t = Validation score   (f1_weighted)\n",
            "\t11.71s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.9146\t = Validation score   (f1_weighted)\n",
            "\t7.4s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.9666\t = Validation score   (f1_weighted)\n",
            "\t47.0s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.9805\t = Validation score   (f1_weighted)\n",
            "\t20.44s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\tTraining LightGBMLarge with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\t0.9568\t = Validation score   (f1_weighted)\n",
            "\t1467.38s\t = Training   runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.9805\t = Validation score   (f1_weighted)\n",
            "\t2.64s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 2885.15s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230519_210435/\")\n"
          ]
        }
      ],
      "source": [
        "predictor = TabularPredictor(label=0,eval_metric='f1_weighted').fit(train_data,num_gpus=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7GO6XHYAGmr"
      },
      "outputs": [],
      "source": [
        "y_p = predictor.predict(test_data.drop([0],axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-vRslGtAwit"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypItCjsqA7Wk",
        "outputId": "57ce8f79-7752-4d0e-aa65-6bdd04120858"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9699087673688592"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_score(y_p,test_data[0],average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "rvbhSqxyAGxt",
        "outputId": "11389de4-f307-4ee6-8760-ce5f1114f89f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  model  score_test  score_val  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0        NeuralNetTorch    0.969857   0.980519        0.208574       0.161214    20.439817                 0.208574                0.161214          20.439817            1       True         12\n",
            "1   WeightedEnsemble_L2    0.969857   0.980519        0.214383       0.162908    23.082009                 0.005809                0.001694           2.642191            2       True         14\n",
            "2       NeuralNetFastAI    0.967627   0.980500        0.212771       0.044941    16.829405                 0.212771                0.044941          16.829405            1       True          3\n",
            "3              CatBoost    0.962610   0.974930        0.313770       0.166630   118.232983                 0.313770                0.166630         118.232983            1       True          8\n",
            "4            LightGBMXT    0.960382   0.966610        0.430904       0.108035   478.274311                 0.430904                0.108035         478.274311            1       True          4\n",
            "5               XGBoost    0.958679   0.966610        0.421402       0.212296    46.999780                 0.421402                0.212296          46.999780            1       True         11\n",
            "6              LightGBM    0.955332   0.966610        0.257324       0.092023   546.901360                 0.257324                0.092023         546.901360            1       True          5\n",
            "7         LightGBMLarge    0.947514   0.956767        0.862735       0.329193  1467.383089                 0.862735                0.329193        1467.383089            1       True         13\n",
            "8      RandomForestEntr    0.927408   0.928835        0.271753       0.113894    86.416256                 0.271753                0.113894          86.416256            1       True          7\n",
            "9      RandomForestGini    0.924032   0.924513        0.306012       0.152889    70.534253                 0.306012                0.152889          70.534253            1       True          6\n",
            "10       ExtraTreesEntr    0.917270   0.914635        0.217300       0.158189     7.399802                 0.217300                0.158189           7.399802            1       True         10\n",
            "11       ExtraTreesGini    0.917212   0.923017        0.220821       0.123374    11.705615                 0.220821                0.123374          11.705615            1       True          9\n",
            "12       KNeighborsDist    0.895250   0.886807        2.667237       0.576921     0.631650                 2.667237                0.576921           0.631650            1       True          2\n",
            "13       KNeighborsUnif    0.894055   0.886807        3.387596       0.570889     0.624755                 3.387596                0.570889           0.624755            1       True          1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dd7f6341-b0b3-4f9c-9c82-a627dcbf4685\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_test</th>\n",
              "      <th>score_val</th>\n",
              "      <th>pred_time_test</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_test_marginal</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NeuralNetTorch</td>\n",
              "      <td>0.969857</td>\n",
              "      <td>0.980519</td>\n",
              "      <td>0.208574</td>\n",
              "      <td>0.161214</td>\n",
              "      <td>20.439817</td>\n",
              "      <td>0.208574</td>\n",
              "      <td>0.161214</td>\n",
              "      <td>20.439817</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.969857</td>\n",
              "      <td>0.980519</td>\n",
              "      <td>0.214383</td>\n",
              "      <td>0.162908</td>\n",
              "      <td>23.082009</td>\n",
              "      <td>0.005809</td>\n",
              "      <td>0.001694</td>\n",
              "      <td>2.642191</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NeuralNetFastAI</td>\n",
              "      <td>0.967627</td>\n",
              "      <td>0.980500</td>\n",
              "      <td>0.212771</td>\n",
              "      <td>0.044941</td>\n",
              "      <td>16.829405</td>\n",
              "      <td>0.212771</td>\n",
              "      <td>0.044941</td>\n",
              "      <td>16.829405</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.962610</td>\n",
              "      <td>0.974930</td>\n",
              "      <td>0.313770</td>\n",
              "      <td>0.166630</td>\n",
              "      <td>118.232983</td>\n",
              "      <td>0.313770</td>\n",
              "      <td>0.166630</td>\n",
              "      <td>118.232983</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LightGBMXT</td>\n",
              "      <td>0.960382</td>\n",
              "      <td>0.966610</td>\n",
              "      <td>0.430904</td>\n",
              "      <td>0.108035</td>\n",
              "      <td>478.274311</td>\n",
              "      <td>0.430904</td>\n",
              "      <td>0.108035</td>\n",
              "      <td>478.274311</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.958679</td>\n",
              "      <td>0.966610</td>\n",
              "      <td>0.421402</td>\n",
              "      <td>0.212296</td>\n",
              "      <td>46.999780</td>\n",
              "      <td>0.421402</td>\n",
              "      <td>0.212296</td>\n",
              "      <td>46.999780</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.955332</td>\n",
              "      <td>0.966610</td>\n",
              "      <td>0.257324</td>\n",
              "      <td>0.092023</td>\n",
              "      <td>546.901360</td>\n",
              "      <td>0.257324</td>\n",
              "      <td>0.092023</td>\n",
              "      <td>546.901360</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LightGBMLarge</td>\n",
              "      <td>0.947514</td>\n",
              "      <td>0.956767</td>\n",
              "      <td>0.862735</td>\n",
              "      <td>0.329193</td>\n",
              "      <td>1467.383089</td>\n",
              "      <td>0.862735</td>\n",
              "      <td>0.329193</td>\n",
              "      <td>1467.383089</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RandomForestEntr</td>\n",
              "      <td>0.927408</td>\n",
              "      <td>0.928835</td>\n",
              "      <td>0.271753</td>\n",
              "      <td>0.113894</td>\n",
              "      <td>86.416256</td>\n",
              "      <td>0.271753</td>\n",
              "      <td>0.113894</td>\n",
              "      <td>86.416256</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RandomForestGini</td>\n",
              "      <td>0.924032</td>\n",
              "      <td>0.924513</td>\n",
              "      <td>0.306012</td>\n",
              "      <td>0.152889</td>\n",
              "      <td>70.534253</td>\n",
              "      <td>0.306012</td>\n",
              "      <td>0.152889</td>\n",
              "      <td>70.534253</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ExtraTreesEntr</td>\n",
              "      <td>0.917270</td>\n",
              "      <td>0.914635</td>\n",
              "      <td>0.217300</td>\n",
              "      <td>0.158189</td>\n",
              "      <td>7.399802</td>\n",
              "      <td>0.217300</td>\n",
              "      <td>0.158189</td>\n",
              "      <td>7.399802</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ExtraTreesGini</td>\n",
              "      <td>0.917212</td>\n",
              "      <td>0.923017</td>\n",
              "      <td>0.220821</td>\n",
              "      <td>0.123374</td>\n",
              "      <td>11.705615</td>\n",
              "      <td>0.220821</td>\n",
              "      <td>0.123374</td>\n",
              "      <td>11.705615</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>KNeighborsDist</td>\n",
              "      <td>0.895250</td>\n",
              "      <td>0.886807</td>\n",
              "      <td>2.667237</td>\n",
              "      <td>0.576921</td>\n",
              "      <td>0.631650</td>\n",
              "      <td>2.667237</td>\n",
              "      <td>0.576921</td>\n",
              "      <td>0.631650</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>KNeighborsUnif</td>\n",
              "      <td>0.894055</td>\n",
              "      <td>0.886807</td>\n",
              "      <td>3.387596</td>\n",
              "      <td>0.570889</td>\n",
              "      <td>0.624755</td>\n",
              "      <td>3.387596</td>\n",
              "      <td>0.570889</td>\n",
              "      <td>0.624755</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd7f6341-b0b3-4f9c-9c82-a627dcbf4685')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd7f6341-b0b3-4f9c-9c82-a627dcbf4685 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd7f6341-b0b3-4f9c-9c82-a627dcbf4685');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
              "0        NeuralNetTorch    0.969857   0.980519        0.208574       0.161214   \n",
              "1   WeightedEnsemble_L2    0.969857   0.980519        0.214383       0.162908   \n",
              "2       NeuralNetFastAI    0.967627   0.980500        0.212771       0.044941   \n",
              "3              CatBoost    0.962610   0.974930        0.313770       0.166630   \n",
              "4            LightGBMXT    0.960382   0.966610        0.430904       0.108035   \n",
              "5               XGBoost    0.958679   0.966610        0.421402       0.212296   \n",
              "6              LightGBM    0.955332   0.966610        0.257324       0.092023   \n",
              "7         LightGBMLarge    0.947514   0.956767        0.862735       0.329193   \n",
              "8      RandomForestEntr    0.927408   0.928835        0.271753       0.113894   \n",
              "9      RandomForestGini    0.924032   0.924513        0.306012       0.152889   \n",
              "10       ExtraTreesEntr    0.917270   0.914635        0.217300       0.158189   \n",
              "11       ExtraTreesGini    0.917212   0.923017        0.220821       0.123374   \n",
              "12       KNeighborsDist    0.895250   0.886807        2.667237       0.576921   \n",
              "13       KNeighborsUnif    0.894055   0.886807        3.387596       0.570889   \n",
              "\n",
              "       fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
              "0     20.439817                 0.208574                0.161214   \n",
              "1     23.082009                 0.005809                0.001694   \n",
              "2     16.829405                 0.212771                0.044941   \n",
              "3    118.232983                 0.313770                0.166630   \n",
              "4    478.274311                 0.430904                0.108035   \n",
              "5     46.999780                 0.421402                0.212296   \n",
              "6    546.901360                 0.257324                0.092023   \n",
              "7   1467.383089                 0.862735                0.329193   \n",
              "8     86.416256                 0.271753                0.113894   \n",
              "9     70.534253                 0.306012                0.152889   \n",
              "10     7.399802                 0.217300                0.158189   \n",
              "11    11.705615                 0.220821                0.123374   \n",
              "12     0.631650                 2.667237                0.576921   \n",
              "13     0.624755                 3.387596                0.570889   \n",
              "\n",
              "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
              "0           20.439817            1       True         12  \n",
              "1            2.642191            2       True         14  \n",
              "2           16.829405            1       True          3  \n",
              "3          118.232983            1       True          8  \n",
              "4          478.274311            1       True          4  \n",
              "5           46.999780            1       True         11  \n",
              "6          546.901360            1       True          5  \n",
              "7         1467.383089            1       True         13  \n",
              "8           86.416256            1       True          7  \n",
              "9           70.534253            1       True          6  \n",
              "10           7.399802            1       True         10  \n",
              "11          11.705615            1       True          9  \n",
              "12           0.631650            1       True          2  \n",
              "13           0.624755            1       True          1  "
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor.leaderboard(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "3jROHIyMAaO5",
        "outputId": "cd87e127-2064-410e-d74c-e27f328d8ea7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7b94480a-aa10-4581-85a5-4729418f1522\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>1760</th>\n",
              "      <th>1761</th>\n",
              "      <th>1762</th>\n",
              "      <th>1763</th>\n",
              "      <th>1764</th>\n",
              "      <th>1765</th>\n",
              "      <th>1766</th>\n",
              "      <th>1767</th>\n",
              "      <th>1768</th>\n",
              "      <th>1769</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8112</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.413942</td>\n",
              "      <td>0.435494</td>\n",
              "      <td>-0.793888</td>\n",
              "      <td>-0.248041</td>\n",
              "      <td>-0.032162</td>\n",
              "      <td>-0.034451</td>\n",
              "      <td>-0.299811</td>\n",
              "      <td>-0.320214</td>\n",
              "      <td>0.085166</td>\n",
              "      <td>...</td>\n",
              "      <td>0.123449</td>\n",
              "      <td>0.770338</td>\n",
              "      <td>-0.102249</td>\n",
              "      <td>-0.015947</td>\n",
              "      <td>0.469086</td>\n",
              "      <td>-0.026474</td>\n",
              "      <td>0.923428</td>\n",
              "      <td>-0.583675</td>\n",
              "      <td>-0.359599</td>\n",
              "      <td>-0.165648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5369</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.434096</td>\n",
              "      <td>0.905136</td>\n",
              "      <td>-0.638856</td>\n",
              "      <td>-0.030171</td>\n",
              "      <td>-0.305138</td>\n",
              "      <td>-0.094247</td>\n",
              "      <td>0.516428</td>\n",
              "      <td>-0.212246</td>\n",
              "      <td>0.536884</td>\n",
              "      <td>...</td>\n",
              "      <td>0.251008</td>\n",
              "      <td>0.129199</td>\n",
              "      <td>-0.007439</td>\n",
              "      <td>-0.141761</td>\n",
              "      <td>-0.186016</td>\n",
              "      <td>0.745377</td>\n",
              "      <td>0.195405</td>\n",
              "      <td>0.287446</td>\n",
              "      <td>0.080846</td>\n",
              "      <td>-0.290372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3768</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.390327</td>\n",
              "      <td>0.350470</td>\n",
              "      <td>-0.588610</td>\n",
              "      <td>-0.284213</td>\n",
              "      <td>-0.000514</td>\n",
              "      <td>0.063387</td>\n",
              "      <td>0.320943</td>\n",
              "      <td>-0.243364</td>\n",
              "      <td>0.496425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.160748</td>\n",
              "      <td>0.180542</td>\n",
              "      <td>-0.092217</td>\n",
              "      <td>0.135577</td>\n",
              "      <td>-0.029392</td>\n",
              "      <td>0.351637</td>\n",
              "      <td>0.350605</td>\n",
              "      <td>-0.347354</td>\n",
              "      <td>-0.126755</td>\n",
              "      <td>0.019912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2076</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.446708</td>\n",
              "      <td>0.349882</td>\n",
              "      <td>-0.312660</td>\n",
              "      <td>-0.357468</td>\n",
              "      <td>-0.260071</td>\n",
              "      <td>0.054856</td>\n",
              "      <td>0.487992</td>\n",
              "      <td>-0.257816</td>\n",
              "      <td>0.339567</td>\n",
              "      <td>...</td>\n",
              "      <td>0.143766</td>\n",
              "      <td>0.085777</td>\n",
              "      <td>-0.108464</td>\n",
              "      <td>0.219048</td>\n",
              "      <td>-0.056512</td>\n",
              "      <td>0.361471</td>\n",
              "      <td>0.129816</td>\n",
              "      <td>-0.610100</td>\n",
              "      <td>0.091250</td>\n",
              "      <td>0.290879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>1</td>\n",
              "      <td>0.231999</td>\n",
              "      <td>0.427252</td>\n",
              "      <td>-0.158172</td>\n",
              "      <td>0.340994</td>\n",
              "      <td>-0.593554</td>\n",
              "      <td>-0.532577</td>\n",
              "      <td>0.566521</td>\n",
              "      <td>-0.463420</td>\n",
              "      <td>0.228979</td>\n",
              "      <td>...</td>\n",
              "      <td>0.165456</td>\n",
              "      <td>0.059883</td>\n",
              "      <td>0.016695</td>\n",
              "      <td>0.061188</td>\n",
              "      <td>0.075182</td>\n",
              "      <td>-0.091003</td>\n",
              "      <td>0.601884</td>\n",
              "      <td>0.240771</td>\n",
              "      <td>0.200379</td>\n",
              "      <td>-0.288484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4373</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.447922</td>\n",
              "      <td>0.095834</td>\n",
              "      <td>-0.638063</td>\n",
              "      <td>-0.051293</td>\n",
              "      <td>-0.133408</td>\n",
              "      <td>0.082636</td>\n",
              "      <td>0.034153</td>\n",
              "      <td>-0.308446</td>\n",
              "      <td>0.223029</td>\n",
              "      <td>...</td>\n",
              "      <td>0.284310</td>\n",
              "      <td>0.284183</td>\n",
              "      <td>-0.130040</td>\n",
              "      <td>0.302741</td>\n",
              "      <td>-0.216126</td>\n",
              "      <td>1.131080</td>\n",
              "      <td>0.094611</td>\n",
              "      <td>-0.307942</td>\n",
              "      <td>0.295619</td>\n",
              "      <td>0.181117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7891</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.366675</td>\n",
              "      <td>0.427856</td>\n",
              "      <td>-0.799431</td>\n",
              "      <td>0.047305</td>\n",
              "      <td>-0.058605</td>\n",
              "      <td>0.175410</td>\n",
              "      <td>-0.201314</td>\n",
              "      <td>-0.599897</td>\n",
              "      <td>-0.154555</td>\n",
              "      <td>...</td>\n",
              "      <td>0.316730</td>\n",
              "      <td>0.063796</td>\n",
              "      <td>0.203215</td>\n",
              "      <td>0.379898</td>\n",
              "      <td>0.475194</td>\n",
              "      <td>-0.315095</td>\n",
              "      <td>0.532730</td>\n",
              "      <td>-0.093904</td>\n",
              "      <td>0.143042</td>\n",
              "      <td>-0.080472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4859</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.096339</td>\n",
              "      <td>0.826361</td>\n",
              "      <td>-0.227779</td>\n",
              "      <td>0.210653</td>\n",
              "      <td>-0.102717</td>\n",
              "      <td>-0.241900</td>\n",
              "      <td>0.251668</td>\n",
              "      <td>-0.224507</td>\n",
              "      <td>-0.079094</td>\n",
              "      <td>...</td>\n",
              "      <td>0.414994</td>\n",
              "      <td>-0.111904</td>\n",
              "      <td>-0.182740</td>\n",
              "      <td>-0.041773</td>\n",
              "      <td>-0.112598</td>\n",
              "      <td>0.382476</td>\n",
              "      <td>0.349130</td>\n",
              "      <td>-0.112907</td>\n",
              "      <td>0.084377</td>\n",
              "      <td>0.386288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3264</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.069547</td>\n",
              "      <td>0.182496</td>\n",
              "      <td>-0.763187</td>\n",
              "      <td>0.410950</td>\n",
              "      <td>-0.668061</td>\n",
              "      <td>-0.134768</td>\n",
              "      <td>-0.171737</td>\n",
              "      <td>-0.089199</td>\n",
              "      <td>0.724893</td>\n",
              "      <td>...</td>\n",
              "      <td>0.120616</td>\n",
              "      <td>0.507855</td>\n",
              "      <td>-0.206666</td>\n",
              "      <td>0.352048</td>\n",
              "      <td>0.327630</td>\n",
              "      <td>0.898148</td>\n",
              "      <td>0.497709</td>\n",
              "      <td>-0.435758</td>\n",
              "      <td>0.265870</td>\n",
              "      <td>0.002601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2732</th>\n",
              "      <td>1</td>\n",
              "      <td>0.142262</td>\n",
              "      <td>0.147684</td>\n",
              "      <td>-0.314760</td>\n",
              "      <td>0.095556</td>\n",
              "      <td>-0.167906</td>\n",
              "      <td>0.334423</td>\n",
              "      <td>0.402583</td>\n",
              "      <td>0.074861</td>\n",
              "      <td>-0.083474</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.281307</td>\n",
              "      <td>0.388400</td>\n",
              "      <td>0.011963</td>\n",
              "      <td>-0.096100</td>\n",
              "      <td>-0.058246</td>\n",
              "      <td>0.728054</td>\n",
              "      <td>-0.255103</td>\n",
              "      <td>0.282228</td>\n",
              "      <td>0.583322</td>\n",
              "      <td>0.037953</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7171 rows × 1769 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b94480a-aa10-4581-85a5-4729418f1522')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b94480a-aa10-4581-85a5-4729418f1522 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b94480a-aa10-4581-85a5-4729418f1522');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      0         2         3         4         5         6         7     \\\n",
              "8112     0 -0.413942  0.435494 -0.793888 -0.248041 -0.032162 -0.034451   \n",
              "5369     2 -0.434096  0.905136 -0.638856 -0.030171 -0.305138 -0.094247   \n",
              "3768     2 -0.390327  0.350470 -0.588610 -0.284213 -0.000514  0.063387   \n",
              "2076     1 -0.446708  0.349882 -0.312660 -0.357468 -0.260071  0.054856   \n",
              "263      1  0.231999  0.427252 -0.158172  0.340994 -0.593554 -0.532577   \n",
              "...    ...       ...       ...       ...       ...       ...       ...   \n",
              "4373     2 -0.447922  0.095834 -0.638063 -0.051293 -0.133408  0.082636   \n",
              "7891     0 -0.366675  0.427856 -0.799431  0.047305 -0.058605  0.175410   \n",
              "4859     2 -0.096339  0.826361 -0.227779  0.210653 -0.102717 -0.241900   \n",
              "3264     2 -0.069547  0.182496 -0.763187  0.410950 -0.668061 -0.134768   \n",
              "2732     1  0.142262  0.147684 -0.314760  0.095556 -0.167906  0.334423   \n",
              "\n",
              "          8         9         10    ...      1760      1761      1762  \\\n",
              "8112 -0.299811 -0.320214  0.085166  ...  0.123449  0.770338 -0.102249   \n",
              "5369  0.516428 -0.212246  0.536884  ...  0.251008  0.129199 -0.007439   \n",
              "3768  0.320943 -0.243364  0.496425  ... -0.160748  0.180542 -0.092217   \n",
              "2076  0.487992 -0.257816  0.339567  ...  0.143766  0.085777 -0.108464   \n",
              "263   0.566521 -0.463420  0.228979  ...  0.165456  0.059883  0.016695   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "4373  0.034153 -0.308446  0.223029  ...  0.284310  0.284183 -0.130040   \n",
              "7891 -0.201314 -0.599897 -0.154555  ...  0.316730  0.063796  0.203215   \n",
              "4859  0.251668 -0.224507 -0.079094  ...  0.414994 -0.111904 -0.182740   \n",
              "3264 -0.171737 -0.089199  0.724893  ...  0.120616  0.507855 -0.206666   \n",
              "2732  0.402583  0.074861 -0.083474  ... -0.281307  0.388400  0.011963   \n",
              "\n",
              "          1763      1764      1765      1766      1767      1768      1769  \n",
              "8112 -0.015947  0.469086 -0.026474  0.923428 -0.583675 -0.359599 -0.165648  \n",
              "5369 -0.141761 -0.186016  0.745377  0.195405  0.287446  0.080846 -0.290372  \n",
              "3768  0.135577 -0.029392  0.351637  0.350605 -0.347354 -0.126755  0.019912  \n",
              "2076  0.219048 -0.056512  0.361471  0.129816 -0.610100  0.091250  0.290879  \n",
              "263   0.061188  0.075182 -0.091003  0.601884  0.240771  0.200379 -0.288484  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "4373  0.302741 -0.216126  1.131080  0.094611 -0.307942  0.295619  0.181117  \n",
              "7891  0.379898  0.475194 -0.315095  0.532730 -0.093904  0.143042 -0.080472  \n",
              "4859 -0.041773 -0.112598  0.382476  0.349130 -0.112907  0.084377  0.386288  \n",
              "3264  0.352048  0.327630  0.898148  0.497709 -0.435758  0.265870  0.002601  \n",
              "2732 -0.096100 -0.058246  0.728054 -0.255103  0.282228  0.583322  0.037953  \n",
              "\n",
              "[7171 rows x 1769 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "fK9rSx9pBxam"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/head_embeddings.pkl','rb') as f:\n",
        "  head_embed_df = pd.read_pickle(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "-fubCwmR57oM",
        "outputId": "0946364e-3034-478d-bf9c-8c7fb34ffe9d"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-62a7449eb477>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhead_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_embed_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;31m# %% ../nbs/00_torch_core.ipynb 153\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All arrays must be of the same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
          ]
        }
      ],
      "source": [
        "head_df = pd.DataFrame(head_embed_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6-2R9_E6e8G"
      },
      "outputs": [],
      "source": [
        "def pickle_to_df(dict_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXE6hek0582V",
        "outputId": "b611c3af-3e13-49c8-c127-989556d6894f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['klikun',\n",
              " array([-6.97019696e-02,  7.76941776e-01, -1.01611897e-01, -4.24751043e-01,\n",
              "         7.39538670e-03, -3.11236262e-01,  6.02114201e-01, -3.68818700e-01,\n",
              "        -1.30258113e-01, -7.84446359e-01,  4.68347728e-01, -3.64642918e-01,\n",
              "        -4.92282450e-01, -6.01461232e-01, -2.00590014e-01,  3.42075050e-01,\n",
              "        -6.63577318e-01,  6.48186982e-01,  1.12197649e+00,  6.68661743e-02,\n",
              "         1.21379428e-01,  1.59148529e-01,  2.73930788e-01, -1.29697025e-02,\n",
              "        -3.92772257e-01,  4.29710746e-01, -7.18206912e-02, -2.67299265e-01,\n",
              "         1.33561581e-01,  6.23888493e-01, -5.96868694e-01, -6.77860081e-02,\n",
              "        -3.10703069e-02, -4.93654817e-01,  6.42050743e-01,  6.69705570e-02,\n",
              "        -7.87684396e-02,  1.13877714e-01, -4.80190545e-01, -2.94320077e-01,\n",
              "         5.01420200e-01, -1.09363604e+00,  1.13799125e-01, -6.45981789e-01,\n",
              "         1.76617205e-02, -8.24058652e-01,  1.13969445e-01, -8.96823108e-02,\n",
              "         3.71058345e-01, -9.14050400e-01, -5.02020597e-01, -1.22506022e-02,\n",
              "         6.18682623e-01,  1.29491925e-01, -1.04781330e-01,  4.17395234e-02,\n",
              "         3.39882374e-01,  3.08806062e-01,  2.16157213e-01,  2.53633618e-01,\n",
              "         5.73423356e-02, -1.75449848e-02, -2.78918356e-01,  1.45921767e-01,\n",
              "        -7.43566155e-02,  4.76040959e-01,  5.64779580e-01, -4.04387265e-01,\n",
              "        -2.17390776e-01, -4.24210697e-01,  9.02075469e-02,  2.04001486e-01,\n",
              "        -4.93972600e-02,  5.72998166e-01,  4.52640414e-01, -8.78096521e-02,\n",
              "        -6.35586753e-02,  1.82317957e-01,  3.39004487e-01,  2.46331915e-01,\n",
              "         1.60347342e-01,  3.86416793e-01,  3.09525013e-01,  2.18701914e-01,\n",
              "        -2.53175557e-01,  1.39747784e-02, -1.54589802e-01,  4.76294488e-01,\n",
              "         4.41545129e-01,  8.22222352e-01, -1.53031182e+00,  5.65541744e-01,\n",
              "        -1.43216372e-01, -1.85847461e-01,  8.43057036e-01,  1.83403611e-01,\n",
              "         9.11064386e-01,  4.94394302e-01,  6.52246237e-01, -1.16158679e-01,\n",
              "         8.24471951e-01, -3.15874785e-01, -7.35013604e-01,  4.31817770e-03,\n",
              "         1.20293796e-02, -7.09759355e-01,  2.67489105e-01, -1.60529435e-01,\n",
              "         9.76128876e-01, -9.20610905e-01, -3.64071816e-01, -6.65799528e-03,\n",
              "         7.57200956e-01,  2.48771906e-01, -3.88116479e-01,  4.61850643e-01,\n",
              "        -3.00691456e-01, -3.31500471e-01, -7.30092525e-02, -7.11902261e-01,\n",
              "         1.05307847e-01, -6.77984804e-02, -1.57177657e-01,  3.90237719e-01,\n",
              "         5.77042699e-02, -6.81636333e-01,  2.04587728e-01, -3.21220487e-01,\n",
              "        -6.40421987e-01,  1.61225066e-01,  4.41212356e-02, -1.30153036e+00,\n",
              "         2.94596940e-01, -1.10127836e-01,  6.65658712e-01, -5.94521463e-01,\n",
              "        -7.21678019e-01, -2.75115728e-01,  4.46038723e-01,  3.83983970e-01,\n",
              "        -9.02738571e-02, -1.05858177e-01,  8.79106671e-02,  2.12532282e-02,\n",
              "         5.65625250e-01,  1.22211665e-01,  6.57067060e-01, -6.07913852e-01,\n",
              "        -2.10529089e-01,  3.51721406e-01, -1.78647786e-01, -7.88726568e-01,\n",
              "         7.48217702e-01,  5.78067899e-01,  4.83567625e-01,  2.83575892e-01,\n",
              "         3.99791420e-01,  3.57652783e-01,  4.47060764e-01, -1.24406517e-02,\n",
              "         1.13027819e-01, -4.74548906e-01,  1.09777391e+00,  9.78174865e-01,\n",
              "        -8.05000812e-02, -6.83410287e-01,  2.91143030e-01, -5.11890471e-01,\n",
              "         4.07443732e-01, -6.44726157e-01,  7.92387843e-01, -3.94818693e-01,\n",
              "         3.44767511e-01, -2.70989656e-01, -2.31121123e-01,  3.12388897e-01,\n",
              "        -5.39794028e-01, -1.29799843e+00,  2.71984190e-01,  1.60121217e-01,\n",
              "         1.90504169e+00,  1.52041733e-01,  3.66933048e-02, -3.12007368e-01,\n",
              "        -3.42833430e-01,  4.50184166e-01, -3.19739521e-01, -8.00853252e-01,\n",
              "         7.59364143e-02, -4.19299513e-01,  8.69791985e-01,  3.26363266e-01,\n",
              "        -4.31255877e-01,  2.67412543e-01, -4.50087160e-01,  1.09983444e+00,\n",
              "         7.27742136e-01,  4.34581697e-01,  7.51854241e-01,  5.44251442e-01,\n",
              "         2.92579502e-01, -4.09666628e-01, -3.31106782e-01,  2.67901540e-01,\n",
              "        -3.01619351e-01,  2.13717446e-01, -7.46897280e-01,  3.53483707e-02,\n",
              "        -1.14842854e-01,  1.53906405e-01,  2.21052468e-02, -1.03707805e-01,\n",
              "         3.03078592e-02,  4.23976004e-01,  3.14313769e-02, -5.31427741e-01,\n",
              "        -2.34947994e-01, -6.56529605e-01,  6.42743111e-01, -6.21900260e-01,\n",
              "        -1.45534229e+00, -4.28067207e-01,  5.07814646e-01, -1.01561002e-01,\n",
              "        -3.13168943e-01, -1.72323957e-01,  7.09411576e-02,  3.65323842e-01,\n",
              "         4.85427320e-01,  2.26193815e-01, -8.30917135e-02,  7.58381486e-01,\n",
              "        -2.51457006e-01,  4.03679907e-02, -3.10284555e-01, -7.60251641e-01,\n",
              "         4.66528267e-01,  3.62721145e-01, -1.93617910e-01,  9.83199477e-03,\n",
              "        -6.55153215e-01,  8.62712860e-02, -2.77287304e-01, -3.65494430e-01,\n",
              "        -4.16577160e-01,  1.02823782e+00, -5.23525536e-01,  2.60463625e-01,\n",
              "        -4.74158645e-01, -7.73659050e-02,  2.20670342e-01, -7.64653236e-02,\n",
              "         7.08955407e-01, -5.40582299e-01,  6.76644146e-01, -1.81930229e-01,\n",
              "        -3.87963593e-01,  5.58885455e-01,  4.77505803e-01, -6.77005529e-01,\n",
              "        -4.94365156e-01,  2.35969752e-01, -5.06242871e-01,  6.74013734e-01,\n",
              "         4.55295086e-01, -4.00508940e-01, -5.97310901e-01,  5.01980782e-01,\n",
              "        -8.09954882e-01, -1.05624884e-01, -1.59773827e-02, -7.29486346e-01,\n",
              "        -8.35611001e-02,  1.74789131e-01,  8.55444819e-02, -1.20732456e-01,\n",
              "        -6.54349029e-01, -2.24743322e-01,  2.68177360e-01,  7.49393880e-01,\n",
              "         1.61152080e-01, -1.25939238e+00,  1.24278709e-01, -5.04289448e-01,\n",
              "         2.11074144e-01, -2.27763087e-01, -6.79277420e-01, -3.45253676e-01,\n",
              "         5.22006035e-01,  4.17444736e-01, -1.46942794e-01,  3.94007921e-01,\n",
              "        -6.55418873e-01,  7.14541972e-02, -5.10742813e-02, -1.74489439e-01,\n",
              "        -7.08577454e-01,  2.72662818e-01,  1.83633983e-01, -6.06115520e-01,\n",
              "        -5.81207871e-02, -4.67743650e-02,  2.34887242e-01, -3.43922049e-01,\n",
              "        -8.49283040e-02,  4.94330257e-01,  9.37817693e-02,  2.41930351e-01,\n",
              "        -4.99030501e-01, -5.66602886e-01,  4.85107899e-01,  8.17269444e-01,\n",
              "        -1.29238427e-01, -7.45077252e-01, -3.82408798e-02, -2.58606136e-01,\n",
              "        -1.72996330e+00, -2.64504820e-01,  2.60933042e-02,  2.16650367e-01,\n",
              "        -1.36672914e-01, -6.54161811e-01,  1.18753767e+00,  1.63890809e-01,\n",
              "         1.42870128e-01,  5.41976869e-01, -6.96648896e-01, -2.31446743e-01,\n",
              "         1.20898992e-01, -2.43210942e-02, -5.75383008e-03,  3.99420261e-02,\n",
              "        -2.51290500e-02,  4.07560408e-01,  8.44392926e-02,  3.72350365e-02,\n",
              "         1.68264434e-01,  7.45778233e-02, -3.60869557e-01,  1.43440634e-01,\n",
              "         6.47429079e-02,  2.16468424e-03,  1.02859586e-01, -4.99697268e-01,\n",
              "        -3.13708246e-01, -1.93040550e-01,  5.31395078e-02,  2.10045755e-01,\n",
              "        -1.10749930e-01, -6.73123002e-02,  7.05098093e-01,  1.67365685e-01,\n",
              "        -3.82202625e-01,  1.11060095e+00, -1.29128337e+00,  1.05785847e-01,\n",
              "         2.01087803e-01,  1.17850304e-02,  1.55775964e-01,  1.60978064e-02,\n",
              "         3.02860379e-01, -4.48171347e-02,  7.29915023e-01, -2.51150429e-01,\n",
              "         1.61747605e-01,  4.52342808e-01, -3.96473467e-01, -6.25756800e-01,\n",
              "        -1.44153774e-01,  8.25813413e-03, -8.94743979e-01, -8.69223773e-02,\n",
              "        -1.77208409e-01,  5.60258999e-02, -5.01314700e-02, -3.43389213e-01,\n",
              "         2.38589406e-01,  4.09801692e-01,  4.64293778e-01, -6.62086904e-02,\n",
              "        -2.33918384e-01,  1.09855533e-02,  3.44480574e-03,  1.08885789e+00,\n",
              "        -3.59398425e-02, -6.03543222e-01, -5.54440916e-03,  5.03784359e-01,\n",
              "        -3.79905403e-01, -2.29972303e-01, -8.86700749e-02,  8.93129408e-02,\n",
              "         6.39167190e-01, -5.56970090e-02,  2.79585123e-01,  3.43964696e-02,\n",
              "         8.50537419e-02, -3.96229655e-01, -5.38134933e-01, -2.67027080e-01,\n",
              "         3.52180123e-01,  6.52603447e-01,  8.25462818e-01,  2.76058316e-02,\n",
              "        -1.99615264e+00,  1.70374781e-01, -5.25130332e-01,  5.48348874e-02,\n",
              "         2.45896250e-01, -5.72065264e-02, -1.57361865e-01, -6.35720015e-01,\n",
              "        -2.37640277e-01, -9.36164093e+00,  2.79370129e-01,  3.21910441e-01,\n",
              "        -3.80629480e-01,  1.70132518e-03,  4.05736268e-01,  2.51915902e-01,\n",
              "        -1.42808998e+00,  9.87656564e-02, -2.83667028e-01, -1.51282489e-01,\n",
              "         1.13511348e+00,  8.66364717e-01,  2.42227733e-01,  6.16342664e-01,\n",
              "         2.10562199e-01, -1.36534050e-01, -7.35548884e-02, -3.72630298e-01,\n",
              "         9.44878161e-02, -1.18805043e-01,  4.65543747e-01, -3.96927387e-01,\n",
              "         4.28713784e-02,  4.02219221e-02, -4.20867145e-01,  8.32823396e-01,\n",
              "         1.48611653e+00,  2.17641741e-02,  5.16600311e-01, -5.75625956e-01,\n",
              "        -7.10495785e-02,  5.86728215e-01,  3.00135612e-01, -1.03689313e-01,\n",
              "         4.44826841e-01, -3.41684818e-01, -5.26027679e-01, -5.15404463e-01,\n",
              "         2.44128481e-01,  3.67972314e-01, -6.59664422e-02, -7.57909119e-02,\n",
              "         9.31310773e-01,  5.10123014e-01, -7.18272269e-01,  7.55795240e-01,\n",
              "        -3.81610751e-01,  3.07077080e-01, -6.71764463e-02,  2.56581593e+00,\n",
              "         3.21210921e-01, -9.63145375e-01, -2.19001323e-01,  9.89721775e-01,\n",
              "         1.38108790e-01,  1.56343371e-01,  2.49215767e-01, -3.91380399e-01,\n",
              "         9.64083493e-01, -3.55645597e-01,  6.75685883e-01, -7.40872979e-01,\n",
              "        -2.67165065e-01, -3.46140683e-01,  7.82210380e-02,  9.41648781e-02,\n",
              "         4.76587862e-02,  1.95287317e-01, -1.53974339e-01, -1.08669683e-01,\n",
              "        -2.65375376e-01, -1.21832192e-02,  8.56028199e-01, -5.33414245e-01,\n",
              "         5.55927396e-01, -7.36817479e-01,  3.45898628e-01, -2.34661460e-01,\n",
              "        -1.07665694e+00, -7.01338172e-01, -4.72099006e-01, -3.56122494e-01,\n",
              "         1.61724523e-01, -7.52754509e-03,  7.14514494e-01,  5.81516385e-01,\n",
              "         2.17420623e-01,  2.65954554e-01, -5.92981100e-01,  2.16345429e-01,\n",
              "        -5.11448324e-01,  1.93218559e-01,  3.58002722e-01, -8.05615664e-01,\n",
              "         2.91456550e-01,  2.62133777e-03, -2.56847680e-01, -1.10783130e-01,\n",
              "         3.70613009e-01, -3.93165588e-01, -1.79883391e-01,  5.65012455e-01,\n",
              "        -1.63233131e-02,  5.39329290e-01, -1.65551081e-01,  8.90802085e-01,\n",
              "         5.53084970e-01, -7.14807689e-01,  2.56976813e-01,  1.02886260e-01,\n",
              "        -1.28228784e-01,  5.68707824e-01,  1.92378253e-01, -2.23416701e-01,\n",
              "        -7.56499767e-01, -1.32120252e-01, -2.71603644e-01,  1.50888056e-01,\n",
              "        -2.21956909e-01,  2.18524337e-02,  4.97373462e-01,  3.45813125e-01,\n",
              "         1.15302825e+00,  5.22820950e-01, -5.12972534e-01,  8.65099132e-02,\n",
              "         6.31805658e-02,  4.60769176e-01,  4.24352705e-01, -4.35144305e-01,\n",
              "         7.28304625e-01,  1.07458615e+00,  6.94644213e-01, -6.36163354e-01,\n",
              "         2.94498175e-01,  6.94162369e-01,  6.54243469e-01,  1.06563151e+00,\n",
              "        -4.83094662e-01, -5.56508839e-01, -1.68595567e-01, -2.42137596e-01,\n",
              "        -5.57140529e-01,  5.14999866e-01, -5.94727695e-01,  6.67906404e-01,\n",
              "         1.69928837e+00, -1.84507579e-01, -3.62462282e-01, -3.46803553e-02,\n",
              "         1.24618673e+00, -2.44536877e-01,  1.88314557e-01, -3.43082756e-01,\n",
              "        -2.46106118e-01,  1.46115333e-01,  1.10000849e-01, -8.42052162e-01,\n",
              "         8.80813241e-01, -1.48352832e-02, -3.83100510e-01,  2.33894914e-01,\n",
              "        -4.28528249e-01,  1.36302680e-01,  8.49293768e-02,  3.71024311e-01,\n",
              "         1.85136169e-01, -8.97366822e-01, -9.95917767e-02, -1.18396610e-01,\n",
              "         7.39119172e-01,  8.02404761e-01,  2.28360027e-01,  8.48420858e-02,\n",
              "         4.07608300e-01, -2.79926479e-01, -6.27981901e-01,  6.11559093e-01,\n",
              "        -6.42183125e-01, -1.05171889e-01, -4.03730631e-01,  1.31006718e-01,\n",
              "         2.52922386e-01, -3.15065861e-01, -1.78194851e-01, -1.60011500e-02,\n",
              "         8.55277777e-02,  3.68767381e-01,  1.84218779e-01,  5.69851220e-01,\n",
              "        -1.13157287e-01, -7.42078662e-01,  1.13798060e-01,  9.52176630e-01,\n",
              "         6.83308065e-01,  3.75707626e-01,  7.34433755e-02,  2.90481299e-02,\n",
              "        -1.07427478e+00,  1.40598714e-01, -3.43340516e-01,  2.62980878e-01,\n",
              "         5.09940267e-01, -8.67382050e-01,  4.65604246e-01, -1.07345626e-01,\n",
              "        -3.19979370e-01,  3.72507602e-01,  3.66933018e-01,  8.24876279e-02,\n",
              "        -1.14302444e+00, -2.67129362e-01, -2.46936828e-01, -5.36770761e-01,\n",
              "        -2.04215989e-01,  7.73833573e-01, -3.83405834e-01, -1.70350075e-01,\n",
              "        -1.73251599e-01, -3.75022739e-02, -5.17921805e-01,  1.69243145e+00,\n",
              "         7.49937654e-01, -7.70877719e-01, -3.70891213e-01, -6.82869673e-01,\n",
              "         6.58363253e-02, -4.11957920e-01,  4.02392328e-01, -6.44894481e-01,\n",
              "         1.00043173e+01,  2.97075331e-01,  4.84626293e-01, -8.13503712e-02,\n",
              "         4.89594579e-01, -4.39072609e-01,  3.70317400e-02, -2.47301310e-02,\n",
              "         1.17863879e-01, -6.67642355e-01, -2.01439828e-01,  5.58027744e-01,\n",
              "        -8.78447965e-02,  1.72996521e-03,  2.69872248e-01,  9.24064875e-01,\n",
              "        -1.46973133e-01,  4.69095975e-01,  2.51415223e-01,  4.58987564e-01,\n",
              "        -2.90385783e-01, -2.51424789e-01,  6.42478466e-01,  5.48963189e-01,\n",
              "        -6.54626012e-01,  2.37968504e-01, -1.10297814e-01, -5.37072539e-01,\n",
              "        -8.82303715e-02,  3.68454486e-01,  2.48160020e-01, -9.51651454e-01,\n",
              "         4.14644539e-01,  1.88083231e-01, -5.19631580e-02,  4.45225835e-01,\n",
              "         2.15374038e-01, -6.97065145e-02, -7.87446648e-02, -1.65221095e-02,\n",
              "         4.84908760e-01,  4.22929525e-01, -5.27632058e-01, -9.13064837e-01,\n",
              "         1.09094411e-01,  7.02202201e-01,  4.56053555e-01,  2.27478787e-01,\n",
              "         2.87774873e+00, -2.40299404e-02, -2.61671066e-01, -6.53286874e-02,\n",
              "         9.78746116e-02, -1.30238719e-02, -4.40310240e-01, -1.99662238e-01,\n",
              "        -8.17103386e-02, -4.86185551e-01,  3.21230918e-01,  8.00123811e-01,\n",
              "        -5.88069558e-02, -2.71400541e-01, -2.53330261e-01, -9.52905118e-02,\n",
              "        -5.24401903e-01,  6.68890029e-02, -3.29555809e-01,  5.10656118e-01,\n",
              "        -5.53523242e-01, -9.69462097e-03, -6.20593488e-01, -1.41228080e-01,\n",
              "        -3.77878726e-01, -1.03488564e-02,  1.07422635e-01, -2.98809111e-01,\n",
              "         3.11553091e-01,  1.49602517e-01, -1.64671093e-02, -1.03176260e+00,\n",
              "         1.73764408e-01, -5.82150161e-01,  3.30031991e-01, -3.21736336e-01,\n",
              "         6.18813336e-01,  2.91730314e-01,  4.97646779e-02,  1.13383830e-02,\n",
              "        -8.12062472e-02, -3.45536828e-01, -1.62836313e-01,  2.61744350e-01,\n",
              "        -5.65773249e-02,  1.59934968e-01,  6.32450879e-01,  4.58511055e-01,\n",
              "         2.08002985e-01, -2.38318264e-01, -3.00886393e-01, -1.07837617e-02,\n",
              "        -1.37689516e-01, -3.96875441e-01,  8.26450467e-01,  1.72299176e-01,\n",
              "        -4.23620045e-01,  4.06962991e-01, -4.87343296e-02,  3.77506167e-01,\n",
              "        -1.47082776e-01,  1.65436745e-01,  4.15200591e-01, -1.06062162e+00,\n",
              "        -1.90379769e-01, -1.65363848e-01, -2.18637988e-01, -2.25793079e-01,\n",
              "         3.40627074e-01,  2.74738103e-01, -2.91135609e-02,  3.51888478e-01,\n",
              "        -1.13853127e-01, -3.49126667e-01,  6.18050814e-01, -2.88561434e-01],\n",
              "       dtype=float32)]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "head_embed_df['klikun'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZfv7F446W8z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
